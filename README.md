# Computer_Vision

import collectionsimport cv2import numpyfrom PIL import Imageimport matplotlib.pyplot as pltclass DigitalImaging:    @staticmethod    def convert_to_gs(image_path):        """        This method gets an image file path as input (.jpg/.png/.jpeg)        It will create a Pillow object and covert it to gray-scale        print the mode of the picture        :param image_path:        :return: picture in gray-scale        """        img_obj = Image.open(image_path)        gray_img = img_obj.convert('L')        return gray_img    @staticmethod    def color_at(img_arr,row_num,column_num):        """        This method returns a tuple of RGB values at a specific coordinate        validate input: both types and value bounds        :param img_arr: image represented as a NumPy array        :param row_num: x value        :param column_num: y value        :return: tuple of (r,g,b)        """        result = DigitalImaging.validate_coordinates(img_arr,row_num,column_num)        if result == 3:            r,g,b = img_arr[row_num][column_num]            print("R,G,B at = ("+str(row_num)+","+str(column_num)+") = "+str(r)+","+str(g)+","+str(b))            return r,g,b        elif result == 1:            grey = img_arr[row_num][column_num]            print("Grey level = ",grey)            return grey    @staticmethod    def validate_coordinates(img_arr,row_num,column_num):        if isinstance(img_arr, numpy.ndarray):            try:                num_of_rows, num_of_columns, channels = img_arr.shape # validate bounds                if isinstance(row_num,int) and isinstance(column_num,int):                    if 0 <= row_num < num_of_rows:                        if 0 <= column_num<num_of_columns:                            return 3                    else:                        raise ValueError("row number not valid")                else:                    raise ValueError("row/column not of int type")            except ValueError:                num_of_rows, num_of_columns = img_arr.shape  # validate bounds                if isinstance(row_num, int) and isinstance(column_num, int):                    if 0 <= row_num < num_of_rows:                        if 0 <= column_num < num_of_columns:                            return 1                    else:                        raise ValueError("row number not valid")                else:                    raise ValueError("row/column not of int type")        else:            raise ValueError("img_arr is not a numpy array")    @staticmethod    def reduce_to(image,char):        img_obj = Image.open(image)        img_arr = numpy.array(img_obj)        if char.upper() == 'R':            img_arr[:, :, (1,2)]=0            return Image.fromarray(img_arr)        if char.upper() == 'G':            img_arr[:, :, (0,2)]=0            return Image.fromarray(img_arr)        if char.upper() == 'B':            img_arr[:, :, (0,1)]=0            return Image.fromarray(img_arr)    @staticmethod    def make_collage(img_arr):        plt.rcParams["figure.figsize"] = [7.50, 3.50]        plt.rcParams["figure.autolayout"] = True        image = plt.imread(img_arr)        titles = ['R', 'G', 'B']        cmaps = [plt.cm.Reds_r, plt.cm.Greens_r, plt.cm.Blues_r]        fig, axes = plt.subplots(1, 3)        objs = zip(axes, (image, *image.transpose(2, 0, 1)), titles, cmaps)        for ax, channel, title, cmap in objs:            ax.imshow(channel, cmap=cmap)            ax.set_title(title)            ax.set_xticks(())            ax.set_yticks(())        plt.show()    @staticmethod    def shapes_dict(images_arr):        d={}        for img in images_arr:            d[numpy.array(img).shape[0]]=numpy.array(img).shape        d2=dict(collections.OrderedDict(sorted(d.items())))        return d2    @staticmethod    def detect_obj(image, str):        # Setup the enviorment by linking to the Haar Cascades Models        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')        eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')        # Identify the image of interest to import. Ensure that when you import a file path        # that you do not use / in front otherwise it will return empty.        img = cv2.imread(image)        # Resize the image to save space and be more manageable.        # We do this by calculating the ratio of the new image to the old image        r = 500.0 / img.shape[1]        dim = (500, int(img.shape[0] * r))        # Perform the resizing and show        resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)        # Display the image        # cv2.imshow('image',resized)        # cv2.waitKey(0) #Before moving on, wait for a keyboard click.        # Process the image - convert to BRG to grey        grey = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)        # cv2.imshow('image',grey)        # cv2.waitKey(0) #Before moving on, wait for a keyboard click.        # Identify the face and eye using the haar-based classifiers.        faces = face_cascade.detectMultiScale(grey, 1.3, 5)        if (str == "face"):            for (x, y, w, h) in faces:                cv2.rectangle(resized, (x, y), (x + w, y + h), (255, 0, 0), 2)                roi_grey = grey[y:y + h, x:x + w]                roi_color = resized[y:y + h, x:x + w]                eyes = eye_cascade.detectMultiScale(roi_grey)        if (str == "eyes"):            for (x, y, w, h) in faces:                roi_grey = grey[y:y + h, x:x + w]                roi_color = resized[y:y + h, x:x + w]                eyes = eye_cascade.detectMultiScale(roi_grey)            for (ex, ey, ew, eh) in eyes:                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)        # Display the bounding box for the face and eyes        cv2.imshow('img', resized)        cv2.waitKey(0)    @staticmethod    def detect_obj_adv(image, bool1, bool2):        if (bool1 == True):            if (bool2 == True):                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')                eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')                img = cv2.imread(image)                r = 500.0 / img.shape[1]                dim = (500, int(img.shape[0] * r))                resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)                grey = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)                faces = face_cascade.detectMultiScale(grey, 1.3, 5)                for (x, y, w, h) in faces:                    cv2.rectangle(resized, (x, y), (x + w, y + h), (255, 0, 0), 2)                    roi_grey = grey[y:y + h, x:x + w]                    roi_color = resized[y:y + h, x:x + w]                    eyes = eye_cascade.detectMultiScale(roi_grey)                for (ex, ey, ew, eh) in eyes:                    cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)                # Display the bounding box for the face and eyes                cv2.imshow('img', resized)                cv2.waitKey(0)            else:                DigitalImaging.detect_obj('../images/henry-cavill.jpg', 'face')        else:            if (bool2 == True):                DigitalImaging.detect_obj('../images/henry-cavill.jpg', 'eyes')            else:                img = cv2.imread(image)                r = 500.0 / img.shape[1]                dim = (500, int(img.shape[0] * r))                # Perform the resizing and show                resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)                # Display the image                cv2.imshow('image', resized)                cv2.waitKey(0)    @staticmethod    def detect_face_in_vid():        # Load the cascade        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')        # To capture video from webcam.        cap = cv2.VideoCapture(0)        while True:            # Read the frame            _, img = cap.read()            # Convert to grayscale            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)            # Detect the faces            faces = face_cascade.detectMultiScale(gray, 1.1, 4)            # Draw the rectangle around each face            for (x, y, w, h) in faces:                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)            # Display            cv2.imshow('Video', img)            # Stop if escape key is pressed            k = cv2.waitKey(30) & 0xff            if k == 27:                break            # Release the VideoCapture object        cap.release()if __name__ == '__main__':    img = Image.open('../images/henry-cavill.jpg')    img_arr = numpy.array(img)# # convert_to_gs#     DigitalImaging.convert_to_gs('../images/henry-cavill.jpg')# # color_at#     DigitalImaging.color_at(img_arr, 100, 100)# # reduce_to#     DigitalImaging.reduce_to('../images/henry-cavill.jpg','R')# # make_collage#     DigitalImaging.make_collage('../images/henry-cavill.jpg')# # shapes_dict#     d={'../images/henry-cavill.jpg','../images/henry-cavill.jpg'}#     DigitalImaging.shapes_dict(d)#detect_obj    DigitalImaging.detect_obj('../images/henry-cavill.jpg', 'face')#     DigitalImaging.detect_obj('../images/henry-cavill.jpg', 'eyes')# #detect_obj_adv#     DigitalImaging.detect_obj_adv('../images/henry-cavill.jpg',False,True)#     DigitalImaging.detect_obj_adv('../images/henry-cavill.jpg',True,True)#     DigitalImaging.detect_obj_adv('../images/henry-cavill.jpg',False,False)#     DigitalImaging.detect_obj_adv('../images/henry-cavill.jpg',True,False)# #detect_face_in_vid#     DigitalImaging.detect_face_in_vid()
